{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb83141b-f8b7-436e-b349-83979445b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0440b49f-e5b4-4114-9580-4be7478c6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a World Cup URL to scrape from footballhistory.org.\n",
      "Type 'exit' or 'quit' to stop.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1930-uruguay.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1930-uruguay.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1934-italy.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1934-italy.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1938-france.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1938-france.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1950-brazil.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1950-brazil.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1954-switzerland.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1954-switzerland.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1958-sweden.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1958-sweden.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1962-chile.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1962-chile.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1966-england.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1966-england.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1970-mexico.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1970-mexico.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1974-west-germany.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1974-west-germany.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1978-argentina.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1978-argentina.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1982-spain.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1982-spain.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1986-mexico.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1986-mexico.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1990-italy.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1990-italy.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1994-unites-states.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1994-unites-states.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/1998-france.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/1998-france.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/2002-korea-japan.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/2002-korea-japan.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/2006-germany.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/2006-germany.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/2010-south-africa.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/2010-south-africa.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/2014-brazil.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/2014-brazil.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/2018-russia.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/2018-russia.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  https://footballhistory.org/world-cup/2022-qatar.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scraped and saved data from: https://footballhistory.org/world-cup/2022-qatar.html\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "URL:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting scraper.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "CSV_FILE = 'worldcup_data_updated.csv'\n",
    "\n",
    "# Initialize CSV file with headers if it doesn't exist\n",
    "if not os.path.exists(CSV_FILE):\n",
    "    with open(CSV_FILE, mode='w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'host', 'year', 'text', 'url'])\n",
    "\n",
    "def scrape_and_save(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to retrieve {url} (status code {response.status_code})\")\n",
    "            return\n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Extract year and host from URL using regex\n",
    "        year_match = re.search(r'/world-cup/(\\d{4})-', url)\n",
    "        year = year_match.group(1) if year_match else \"Unknown\"\n",
    "\n",
    "        host_match = re.search(r'/world-cup/\\d{4}-(.+?).html', url)\n",
    "        host = host_match.group(1).replace('-', ' ').title() if host_match else \"Unknown\"\n",
    "\n",
    "        main_sections = [\"Background\", \"Format\", \"Cities and arenas\", \"Tournament\", \"Results\", \"Aftermath\"]\n",
    "        sidebar_sections = [\"Participating teams\", \"1st, 2nd and 3rd places\", \"Top scorers\", \"Cities and stadiums\"]\n",
    "\n",
    "        content_parts = []\n",
    "\n",
    "        # Extract <h1> and intro paragraphs before first h2/h3\n",
    "        h1 = soup.find('h1')\n",
    "        if h1:\n",
    "            title = h1.get_text(strip=True)\n",
    "            content_parts.append(f\"{title}\\n{'=' * len(title)}\")\n",
    "            for sibling in h1.find_next_siblings():\n",
    "                if sibling.name in ['h2', 'h3']:\n",
    "                    break\n",
    "                if sibling.name == 'p':\n",
    "                    content_parts.append(sibling.get_text(\" \", strip=True))\n",
    "        else:\n",
    "            print(\"No <h1> title found.\")\n",
    "\n",
    "        # Extract specified main sections\n",
    "        for header in soup.find_all(['h2', 'h3']):\n",
    "            header_text = header.get_text(strip=True)\n",
    "            if header_text in main_sections:\n",
    "                content_parts.append(f\"\\n{header_text}\\n{'-' * len(header_text)}\")\n",
    "                for sibling in header.find_next_siblings():\n",
    "                    if sibling.name in ['h2', 'h3']:\n",
    "                        break\n",
    "                    if sibling.name == 'p':\n",
    "                        content_parts.append(sibling.get_text(\" \", strip=True))\n",
    "\n",
    "        # Extract sidebar sections from <div class=\"fact\">\n",
    "        fact_box = soup.find(\"div\", class_=\"fact\")\n",
    "        if fact_box:\n",
    "            for tag in fact_box.find_all(['h3', 'ul', 'p'], recursive=False):\n",
    "                if tag.name == 'h3':\n",
    "                    heading = tag.get_text(strip=True)\n",
    "                    if heading in sidebar_sections:\n",
    "                        content_parts.append(f\"\\n{heading}\\n{'-' * len(heading)}\")\n",
    "                elif tag.name == 'ul':\n",
    "                    items = [li.get_text(\" \", strip=True) for li in tag.find_all('li')]\n",
    "                    content_parts.extend(items)\n",
    "                elif tag.name == 'p':\n",
    "                    text = tag.get_text(\" \", strip=True)\n",
    "                    if text:\n",
    "                        content_parts.append(text)\n",
    "\n",
    "        final_text = \"\\n\".join(content_parts).strip()\n",
    "        if not final_text:\n",
    "            final_text = \"[No content extracted]\"\n",
    "\n",
    "        record_id = str(uuid.uuid4())\n",
    "\n",
    "        # Append to CSV\n",
    "        with open(CSV_FILE, mode='a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([record_id, host, year, final_text, url])\n",
    "\n",
    "        print(f\"‚úÖ Scraped and saved data from: {url}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error scraping {url}: {e}\")\n",
    "\n",
    "# === CLI loop ===\n",
    "print(\"Enter a World Cup URL to scrape from footballhistory.org.\")\n",
    "print(\"Type 'exit' or 'quit' to stop.\\n\")\n",
    "\n",
    "while True:\n",
    "    url = input(\"URL: \").strip()\n",
    "    if url.lower() in ['exit', 'quit']:\n",
    "        print(\"Exiting scraper.\")\n",
    "        break\n",
    "    if not url.startswith(\"http\"):\n",
    "        print(\"‚ö†Ô∏è Please enter a valid URL starting with http or https.\")\n",
    "        continue\n",
    "\n",
    "    scrape_and_save(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da3cf6f-989d-46c5-96b8-48df464bd782",
   "metadata": {},
   "source": [
    "This is a **web scraper** that extracts **World Cup data from a specific webpage** (e.g., from `footballhistory.org`) and saves it into a **CSV file**.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° **High-Level Purpose:**\n",
    "\n",
    "To **scrape World Cup history pages**, extract useful sections like the title, format, results, scorers, etc., and **store the cleaned data** in a CSV file for later use (e.g., in a chatbot or database).\n",
    "\n",
    "---\n",
    "\n",
    "### üß© **How it Works:**\n",
    "\n",
    "#### ‚úÖ 1. **Set Up the CSV File**\n",
    "\n",
    "* The code first checks if `worldcup_data_updated.csv` exists.\n",
    "* If it doesn't, it **creates the file** and writes headers:\n",
    "  `['id', 'host', 'year', 'text', 'url']`.\n",
    "\n",
    "---\n",
    "\n",
    "#### üåê 2. **Scrape a Given URL**\n",
    "\n",
    "Function: `scrape_and_save(url)`\n",
    "\n",
    "##### üîç a. **Get Webpage Content**\n",
    "\n",
    "* Uses `requests.get()` to fetch the HTML from the given URL.\n",
    "* Parses the page using `BeautifulSoup`.\n",
    "\n",
    "##### üóìÔ∏è b. **Extract Metadata from URL**\n",
    "\n",
    "* **Year** and **host country** are extracted from the URL using regular expressions.\n",
    "\n",
    "  * Example: From `https://.../world-cup/1998-france.html`, it gets:\n",
    "\n",
    "    * Year = `1998`\n",
    "    * Host = `France`\n",
    "\n",
    "---\n",
    "\n",
    "#### üìë 3. **Extract Web Page Content**\n",
    "\n",
    "The scraper collects content from:\n",
    "\n",
    "##### üìå a. **Main Content Sections**\n",
    "\n",
    "* From the main article, it looks for headings like:\n",
    "\n",
    "  * `\"Background\"`, `\"Format\"`, `\"Tournament\"`, etc.\n",
    "* It grabs:\n",
    "\n",
    "  * The **title** (`<h1>`)\n",
    "  * Paragraphs under those headings until the next heading appears.\n",
    "\n",
    "##### üì¶ b. **Sidebar \"Fact Box\" Sections**\n",
    "\n",
    "* From the `<div class=\"fact\">` sidebar, it extracts headings like:\n",
    "\n",
    "  * `\"Top scorers\"`, `\"Participating teams\"`, etc.\n",
    "* Pulls out list items (`<ul><li>`), small paragraphs, and headers.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßæ 4. **Compile and Save the Text**\n",
    "\n",
    "* It combines all extracted content into a readable `final_text`.\n",
    "* If nothing is extracted, it adds a placeholder.\n",
    "\n",
    "#### üÜî 5. **Save to CSV**\n",
    "\n",
    "* Creates a unique ID (`uuid4`) for the record.\n",
    "* Saves a new row to the CSV with:\n",
    "\n",
    "  * `id`, `host`, `year`, `text`, `url`\n",
    "\n",
    "---\n",
    "\n",
    "### üßë‚Äçüíª 6. **Command-Line Interface (CLI)**\n",
    "\n",
    "* Prompts the user to **enter a URL**.\n",
    "* Scrapes it and saves the data.\n",
    "* Allows repeated scraping by re-entering URLs.\n",
    "* You can type **'exit' or 'quit'** to stop the program.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Example Output Row in CSV:\n",
    "\n",
    "| id | host | year | text (cleaned summary) | url |\n",
    "| -- | ---- | ---- | ---------------------- | --- |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è Tech Stack:\n",
    "\n",
    "* `requests`: for HTTP requests\n",
    "* `BeautifulSoup`: for HTML parsing\n",
    "* `csv`: for saving structured data\n",
    "* `uuid`: for generating unique IDs\n",
    "* `re`: for regular expressions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e854eb0-89ac-4fbd-84e5-0d925fcfc9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wcproject",
   "language": "python",
   "name": "wcproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
